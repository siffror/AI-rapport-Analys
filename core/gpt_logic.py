import os
import openai
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity

# üîê Ladda API-nyckel fr√•n milj√∂variabler (Streamlit Secrets eller .env)
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# üß† Generera embedding fr√•n en textstr√§ng
# core/gpt_logic.py

def get_embedding(text: str):
    try:
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        import traceback
        print("‚ùå Full traceback:", traceback.format_exc())  # Visar hela felet i loggen
        raise RuntimeError(f"‚ùå Fel vid skapande av embedding: {e}")


# üîç S√∂k relevanta chunkar baserat p√• fr√•gan
def search_relevant_chunks(question: str, embedded_chunks: list, top_k: int = 3):
    query_embed = get_embedding(question)
    similarities = []

    for item in embedded_chunks:
        score = cosine_similarity([query_embed], [item["embedding"]])[0][0]
        similarities.append((score, item["text"]))

    top_chunks = sorted(similarities, reverse=True)[:top_k]
    context = "\n---\n".join([chunk for _, chunk in top_chunks])

    return context, top_chunks

# ü§ñ Generera svar med GPT-4o
def generate_gpt_answer(question: str, context: str) -> str:
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Du √§r en AI som analyserar √•rsrapporter fr√•n f√∂retag. "
                        "Besvara anv√§ndarens fr√•ga baserat enbart p√• den kontext du f√•r. "
                        "Var s√• specifik som m√∂jligt, och om siffror, nyckeltal eller direkta formuleringar fr√•n texten finns ‚Äì inkludera dem tydligt. "
                        "Svar ska vara konkreta, g√§rna med punktlistor eller direkta utdrag fr√•n rapporten d√§r det √§r relevant."
                    )
                },
                {
                    "role": "user",
                    "content": f"Anv√§nd nedanst√•ende information f√∂r att besvara fr√•gan:\n{context}\n\nFr√•ga: {question}"
                }
            ],
            temperature=0.3,
            max_tokens=700
        )
        return response.choices[0].message.content
    except Exception as e:
        raise RuntimeError(f"‚ùå GPT-f√∂rfr√•gan misslyckades: {e}")
