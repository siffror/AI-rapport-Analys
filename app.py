import os
import pickle
import hashlib
import requests
import re
from bs4 import BeautifulSoup
import fitz  # PyMuPDF
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from fpdf import FPDF
from core.gpt_logic import search_relevant_chunks, generate_gpt_answer, get_embedding
from utils import extract_noterade_bolag_table
from ocr_utils import extract_text_from_image_or_pdf
import pdfplumber
import openai

# --- MiljÃ¶instÃ¤llningar ---
load_dotenv()

# --- Cache-funktioner ---
def get_embedding_cache_name(source_id: str) -> str:
    hashed = hashlib.md5(source_id.encode("utf-8")).hexdigest()
    return os.path.join("embeddings", f"embeddings_{hashed}.pkl")

def save_embeddings(filename, data):
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    with open(filename, "wb") as f:
        pickle.dump(data, f)

def load_embeddings_if_exists(filename):
    if os.path.exists(filename):
        with open(filename, "rb") as f:
            return pickle.load(f)
    return None

# --- Textutvinning ---
def extract_text_from_file(file):
    text_output = ""

    if file.name.endswith(".pdf"):
        file.seek(0)
        try:
            with pdfplumber.open(file) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text_output += page_text + "\n"
                    tables = page.extract_tables()
                    for table in tables:
                        for row in table:
                            clean_row = "\t".join(cell.strip() if cell else "" for cell in row)
                            text_output += clean_row + "\n"
        except Exception as e:
            text_output += f"\n[âš ï¸ Kunde inte lÃ¤sa PDF med pdfplumber: {e}]"

    elif file.name.endswith(".html"):
        soup = BeautifulSoup(file.read(), "html.parser")
        for tag in soup(["script", "style", "nav", "footer", "header"]):
            tag.decompose()
        text_output = soup.get_text(separator="\n")

    elif file.name.endswith((".xlsx", ".xls")):
        df = pd.read_excel(file)
        text_output = df.to_string(index=False)

    return text_output

@st.cache_data(show_spinner=False)
def fetch_html_text(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.content, "html.parser")
        for tag in soup(["script", "style", "nav", "footer", "header"]):
            tag.decompose()
        tables = soup.find_all("table")
        table_texts = []
        for table in tables:
            rows = table.find_all("tr")
            for row in rows:
                cells = row.find_all(["td", "th"])
                line = "\t".join(cell.get_text(strip=True) for cell in cells)
                if line:
                    table_texts.append(line)
        body_text = soup.get_text(separator="\n")
        clean_lines = [line.strip() for line in body_text.splitlines() if line.strip()]
        cleaned_text = "\n".join(clean_lines)
        return cleaned_text + "\n\n[TABELLINNEHÃ…LL]\n" + "\n".join(table_texts)
    except:
        return None

# --- Chunking & filtrering ---
def chunk_text(text, chunk_size=1000, overlap=200):
    lines = text.split("\n")
    chunks, current, total_length = [], [], 0
    for line in lines:
        line = line.strip()
        if not line:
            continue
        current.append(line)
        total_length += len(line)
        if total_length >= chunk_size:
            chunks.append("\n".join(current))
            current, total_length = [], 0
    if current:
        chunks.append("\n".join(current))
    return chunks

def is_key_figure(row):
    patterns = [
        r"\b\d+[\.,]?\d*\s*(SEK|MSEK|kr|miljoner|tkr|USD|\$|\u20ac|%)",
        r"(resultat|omsÃ¤ttning|utdelning|kassaflÃ¶de|kapital|intÃ¤kter|EBITDA|vinst).*?\d"
    ]
    return any(re.search(p, row, re.IGNORECASE) for p in patterns)

# --- GPT: Full rapportanalys ---
def full_rapportanalys(text: str) -> str:
    system_prompt = (
        "Du Ã¤r en erfaren finansiell analytiker med djup fÃ¶rstÃ¥else fÃ¶r fÃ¶retagsekonomi, strategi och rapportanalys. "
        "Du fÃ¥r en Ã¥rsrapport eller annan finansiell text och ska gÃ¶ra en komplett analys av bolaget baserat pÃ¥ innehÃ¥llet. "
        "Analysera kreativt, identifiera mÃ¶nster, tolka siffror, och lyft fram bÃ¥de styrkor, svagheter, risker och mÃ¶jligheter. "
        "Om nÃ¥got verkar saknas eller Ã¤r oklart â€“ kommentera det. Dra slutsatser dÃ¤r det Ã¤r mÃ¶jligt, men gissa aldrig. "
        "Ge en strukturerad analys med rubriker som: Ã–versikt, Finansiell Sammanfattning, VÃ¤sentliga HÃ¤ndelser, Risker, Kommentarer. "
        "Svara pÃ¥ samma sprÃ¥k som texten du fÃ¥r, oavsett om det Ã¤r svenska, engelska eller annat. "
        "Om anvÃ¤ndaren stÃ¤ller en frÃ¥ga pÃ¥ annat sprÃ¥k Ã¤n rapporten â€“ anpassa svaret till frÃ¥gesprÃ¥ket, men citera frÃ¥n originaltexten dÃ¤r det Ã¤r relevant."
    )
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ],
            temperature=0.3,
            max_tokens=1500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ Fel vid analys: {e}"
        
# ğŸŒ UI
st.set_page_config(page_title="ğŸ“Š AI Rapportanalys", layout="wide")
st.markdown("<h1 style='color:#3EA6FF;'>ğŸ“Š AI-baserad Rapportanalys</h1>", unsafe_allow_html=True)
st.image("https://www.appypie.com/dharam_design/wp-content/uploads/2025/05/headd.svg", width=120)

html_link = st.text_input("ğŸŒ Rapport-lÃ¤nk (HTML)")
uploaded_file = st.file_uploader("ğŸ“ Ladda upp HTML, PDF, Excel eller bild", type=["html", "pdf", "xlsx", "xls", "png", "jpg", "jpeg"])

preview = ""
ocr_text = ""

# ğŸ“¥ Filhantering
if uploaded_file:
    if uploaded_file.name.endswith((".png", ".jpg", ".jpeg")):
        ocr_text, _ = extract_text_from_image_or_pdf(uploaded_file)
        st.text_area("ğŸ“„ OCR-utlÃ¤st text frÃ¥n bild:", ocr_text[:2000], height=200)

        if st.button("ğŸ” Analysera bildtext med GPT"):
            gpt_prompt = (
                "HÃ¤r Ã¤r en tabell hÃ¤mtad frÃ¥n en bild av en finansiell rapport.\n"
                "RÃ¤kna hur mÃ¥nga noterade bolag som listas:\n\n"
                f"{ocr_text}"
            )
            answer = generate_gpt_answer("Hur mÃ¥nga noterade bolag listas?", gpt_prompt)
            st.markdown("### ğŸ¤– GPT-4o svar:")
            st.write(answer)

    elif uploaded_file.name.endswith((".pdf", ".html", ".xlsx", ".xls")):
        preview = extract_text_from_file(uploaded_file)

elif html_link:
    st.info("ğŸ” HÃ¤mtar innehÃ¥ll...")
    preview = fetch_html_text(html_link)
else:
    preview = st.text_area("âœï¸ Klistra in text manuellt hÃ¤r:", "", height=200)

# Kombinera extraherad text
text_to_analyze = preview or ocr_text

if preview:
    st.text_area("ğŸ“„ FÃ¶rhandsvisning:", preview[:5000], height=200)
else:
    st.warning("âŒ Ingen text att analysera Ã¤n.")

# ğŸ” FullstÃ¤ndig rapportanalys
if st.button("ğŸ” FullstÃ¤ndig rapportanalys"):
    with st.spinner("ğŸ“Š GPT analyserar hela rapporten..."):
        if text_to_analyze:
            full_summary = full_rapportanalys(text_to_analyze)
            st.markdown("### ğŸ§¾ FullstÃ¤ndig AI-analys:")
            st.markdown(full_summary)
            st.download_button("ğŸ’¾ Ladda ner fullstÃ¤ndig analys (.txt)", full_summary, file_name="full_rapportanalys.txt")
        else:
            st.error("Ingen text tillgÃ¤nglig fÃ¶r analys.")

# ğŸ§  FrÃ¥ga och GPT-svar
if "user_question" not in st.session_state:
    st.session_state.user_question = "Vilken utdelning per aktie fÃ¶reslÃ¥s?"

st.text_input("FrÃ¥ga:", key="user_question")
user_question = st.session_state.user_question

if text_to_analyze and len(text_to_analyze.strip()) > 20:
    if st.button("ğŸ” Analysera med GPT"):
        with st.spinner("ğŸ¤– GPT analyserar..."):
            source_id = html_link or (uploaded_file.name if uploaded_file else text_to_analyze[:50])
            cache_file = get_embedding_cache_name(source_id)
            embedded_chunks = load_embeddings_if_exists(cache_file)

            if not embedded_chunks:
                chunks = chunk_text(text_to_analyze)
                embedded_chunks = []
                for i, chunk in enumerate(chunks, 1):
                    try:
                        st.write(f"ğŸ”¹ Chunk {i} â€“ {len(chunk)} tecken")
                        embedding = get_embedding(chunk)
                        embedded_chunks.append({"text": chunk, "embedding": embedding})
                    except Exception as e:
                        st.error(f"âŒ Fel vid embedding av chunk {i}: {e}")
                        st.stop()
                save_embeddings(cache_file, embedded_chunks)

            context = "\n---\n".join(chunk["text"] for chunk in embedded_chunks)

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"{context}\n\nFrÃ¥ga: {user_question}"}
            ]

            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.3,
                max_tokens=1500
            )

            answer = response.choices[0].message.content

            

            st.success("âœ… Svar klart!")
            st.markdown("### ğŸ¤– GPT-4o svar:")
            st.info(answer)

            # Filtrera nyckeltal och undvik dubbletter
            key_figures = list(set(
                row.strip() for row in answer.split("\n")
                if is_key_figure(row) and len(row.strip()) > 10
            ))
            if st.checkbox("ğŸ” Visa hela GPT-kontext (debug)"):
                st.text_area("ğŸ§  GPT fÃ¥r denna text:", context[:10000], height=300)

            if "ingen specifik information om fÃ¶reslagen utdelning" in answer.lower():
                st.warning("âš ï¸ GPT hittade ingen specifik information om fÃ¶reslagen utdelning. Du kan behÃ¶va kontrollera Ã¥rsrapportens senare delar eller separata utdelningsbesked.")
            elif key_figures:
                st.markdown("### ğŸ“Š MÃ¶jliga nyckeltal i svaret:")
                for row in key_figures:
                    st.markdown(f"- {row}")

        

            st.download_button("ğŸ’¾ Ladda ner svar (.txt)", answer, file_name="gpt_svar.txt")

            pdf = FPDF()
            pdf.add_page()
            pdf.set_font("Arial", size=12)
            for line in answer.split("\n"):
                pdf.multi_cell(0, 10, line)
            st.download_button("ğŸ“„ Ladda ner svar (.pdf)", pdf.output(dest="S").encode("latin1"), file_name="gpt_svar.pdf")
else:
    st.info("ğŸ“ Ange text, lÃ¤nk eller ladda upp en fil eller bild fÃ¶r att bÃ¶rja.")

